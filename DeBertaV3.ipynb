{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211382,"status":"ok","timestamp":1714388336960,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"o7KgAGXBJJ4i","outputId":"7712d531-81d9-40b2-c237-3482f3cdc562"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wandb\n","  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Collecting transformers\n","  Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.40.0\n","    Uninstalling transformers-4.40.0:\n","      Successfully uninstalled transformers-4.40.0\n","Successfully installed transformers-4.40.1\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->bitsandbytes)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->bitsandbytes)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->bitsandbytes)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->bitsandbytes)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->bitsandbytes)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->bitsandbytes)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->bitsandbytes)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->bitsandbytes)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->bitsandbytes)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->bitsandbytes)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->bitsandbytes)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n","Successfully installed bitsandbytes-0.43.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["!pip install --upgrade wandb\n","!pip install --upgrade transformers\n","!pip install -q bitsandbytes-cuda110\n","!pip install sentencepiece\n","!pip install bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7caZEFHKePm"},"outputs":[],"source":["# import manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# import Pytorch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.checkpoint import checkpoint\n","from torch.autograd import Variable\n","\n","# import wandb\n","import wandb\n","\n","import tokenizers\n","\n","# import Transformer model\n","import transformers\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW\n","from transformers import DataCollatorWithPadding\n","from transformers.models.deberta_v2.modeling_deberta_v2 import StableDropout, ContextPooler\n","\n","# import SKLearn\n","from sklearn.model_selection import  KFold, GroupKFold, StratifiedKFold, StratifiedGroupKFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import log_loss\n","\n","\n","# import ...\n","import string\n","import random\n","import os\n","import joblib\n","import gc\n","import copy\n","import time\n","\n","\n","# other\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","#8-bits optimizer\n","import bitsandbytes as bnb\n","\n","# from codecarbon import track_emissions\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1714388354335,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"WSlBC0f7KhGx","outputId":"e2698927-c6eb-4bd5-b8b8-cb5bf0ef63bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 2.2.1+cu121\n","tokenizers.__version__: 0.19.1\n","transformers.__version__: 4.40.1\n"]}],"source":["print(f\"torch.__version__: {torch.__version__}\")\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3174,"status":"ok","timestamp":1714388357505,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"G6a7cU0ALa2M","outputId":"4f4e49f1-bf45-4771-9e92-a5127075f49a"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import userdata\n","\n","# Get secret key from kaggle\n","# Go to Add-ons -> Secrets and provide your Wandb access token with Label name as wandb_api and value from https://wandb.ai/authorize\n","api_key = userdata.get(\"wandb_api\")\n","\n","# Connect to wandb\n","wandb.login(key=api_key)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254,"referenced_widgets":["1d794d0897b141028fd148785fecf750","dfd95812caf942c2a003eb6f2ea7065a","fe356aea8e544c8db287570186264cc9","8f009bb89214484fa8fd60b4f94239d7","1245849d543840e19579d979d3fae178","24485f84b9994abeb7d4ab115657a6e1","197a8b682120422ba57f7d9d22e2359d","26afc87c74294211bc128d57d5e23c04","32bef58805ad4aa9bd0f30529b200763","ed8800f38ae74aeea28f296ba65511fa","f687bdfc939d4f3f84c829fc02a866f8","57b522f2a18e4056827e041d7fcdd49e","90420d5cad4a495da4fa80ac667ed1a8","dc2483b5e5dc470d935fe9c37829c82a","69220dd2fffc48f586ebe975e3a017c9","eda173525ec84715ba80fa3e1d2c8e41","968b7ecf72ae4eab8b6ad777f74cc605","622de59072804732916c20fd04478820","e98c25ef37c64069a627cd05390d8dbe","98f27a8105f641f79b4de4a41893f8e3","daaf4dd6cb8a495982c18678512325e7","83ee34a8caf040b399294a76a9f54d82","505f52e3f54e45269e83f44deeeb816a","7b7086a1959340b2b3633153f3923c09","940dc8cbfedc4dc0bac54f7b0ff5853c","6982c089339842fa9930b99cf0827c8b","873cbeecb91e41148a920e2545f04094","41f0b54f230d4ece8f7c352bd91932a1","9a64385da46547cba7004202a8bc631a","bd7fb776a19d42b4a22177cb33051f26","78739ba341284a1a8ebc734d09fa4d12","31bd8b171f9a44df9a7db0289d5f17a2","7c43b4a2df6e4ae89b3aa5ff9bee76aa"]},"executionInfo":{"elapsed":4172,"status":"ok","timestamp":1714388361675,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"4kLtZ2iHMZzO","outputId":"01f11547-10f7-432a-f107-4c3e936b4ff0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d794d0897b141028fd148785fecf750","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57b522f2a18e4056827e041d7fcdd49e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"505f52e3f54e45269e83f44deeeb816a","version_major":2,"version_minor":0},"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["False"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["class CFG:\n","    seed = 2022\n","    max_length = 512\n","    epoch = 4\n","    train_batch_size = 16\n","    valid_batch_size = 32\n","\n","    model_name = \"microsoft/deberta-v3-base\"\n","    token_name = \"microsoft/deberta-v3-base\"\n","\n","    scheduler = \"CosineAnnealingLR\"\n","    learning_rate = 1e-5\n","    min_lr = 1e-6\n","    T_max = 500\n","    weight_decay = 0.005\n","    dropout = 0.1\n","\n","    num_classes = 2\n","    n_fold = 3\n","    n_accumulate = 2\n","    freezing = True\n","    gradient_checkpoint = True\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    wandb_id = f\"PL{round(time.time())}\" # ID on WandB\n","    group = f'{wandb_id}-Baseline'\n","    competition = \"Multi-author\"\n","    _wandb_kernel = \"deb\"\n","\n","CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.token_name, use_fast=False)\n","CFG.tokenizer.model_max_length = CFG.max_length\n","CFG.tokenizer.is_fast"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1714388361676,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"OnJElwwyMlrc","outputId":"f2d5edd0-2fc9-47bf-9e41-43979227f29b"},"outputs":[{"data":{"text/plain":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.40.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["AutoConfig.from_pretrained(CFG.model_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10FpbmIqNy8M"},"outputs":[],"source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=CFG.seed)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ug2El2dsN4qL"},"outputs":[],"source":["def criterion(outputs, labels):\n","    \"\"\"\n","    Calculate Cross Entropy Loss\n","    \"\"\"\n","    return nn.CrossEntropyLoss()(outputs, labels)\n","\n","def get_score(outputs, labels):\n","    \"\"\"\n","    Calculate Log Loss from softmax output\n","    \"\"\"\n","    outputs = F.softmax(torch.tensor(outputs)).numpy()\n","    return log_loss(labels, outputs)\n","\n","def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","\n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","\n","    return freezed_parameters\n","\n","# 8-bits optimizer\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","\n","        if hasattr(embeddings_path, attr_name):\n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324655,"status":"ok","timestamp":1714388686328,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"711sN8XUPsO7","outputId":"38b6cec5-b61f-41c5-e2ef-482316bfc729"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Now, you can access files in your Google Drive\n","# For example, to read a text file\n","INPUT_DIR = '/data'\n","\n","TRAIN_CSV = os.path.join(INPUT_DIR, \"train-table-mediumparser.csv\")\n","\n","TEST_CSV = os.path.join(INPUT_DIR, \"eval-table-mediumparser.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":2143,"status":"ok","timestamp":1714388688467,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"RN3-voRnRTCs","outputId":"1c31447c-e21d-4be7-830f-a9fccfc18702"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df\",\n  \"rows\": 51993,\n  \"fields\": [\n    {\n      \"column\": \"Paragraphs1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43193,\n        \"samples\": [\n          \"This will also accelerate exploration of Starlink alternatives because no user wants to see a critical service be subject to the whims of an asshat plutocrat.\",\n          \"Yes! The funds would be apportioned to the states and tribal governments to implement their Wildlife Action Plans, so it really depends on whether that state has listed invasive species as a threat to rare native wildlife (aka species of greatest conservation need) in their plan. But they all do.\",\n          \"\\\"Number 1: Russia's, of course Number 2: Big parade, with fireworks, dancers, a huge band in The Red Square, with blackjack and hookers Number 3: Soon Like, very soon, sooner than you'd think...any day now...I swear it will come very quickly GLORY TO RUSSIA!\\\".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Paragraphs2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44655,\n        \"samples\": [\n          \"Corruption in the uk is substantially less of a problem than Ukraine... ukraine is the most corrupted country in Europe after russia and Belarus if i am not mistaken.\",\n          \"I'd love to get back to 2 actual political parties, not what we have now - Democrats vs. QAnon/Fascist/Confederate revivalist/Big Lie spreading wolves in sheep's clothing.\",\n          \"I'm not going to hold my breath waiting for a GOP-led House to investigate an ethics violation of one of their own. They're too busy prepping the endless investigations into Hunter Biden revenge porn to care about actual ethics. Over half of the new committee chairs literally voted not to certify Biden's election win. Jim Jordan just got the chair position for the House judiciary committee. Yes, the same Jim Jordan that flagrantly refused to cooperate with the requests of another House committee. The same Jim Jordan that said the American public is tired of endless House investigations yet is prepping to open dozens once he gets his gavel. The same Jim Jordan that accused Democrats of unethically using committees as political cudgels is...you guessed it...about to do the same. Such unabashed hypocrites, the House GOP is completely amoral.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Truth_changes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1210,\n        \"min\": 1,\n        \"max\": 4200,\n        \"num_unique_values\": 4200,\n        \"samples\": [\n          2568,\n          2976\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df"},"text/html":["\n","  <div id=\"df-a00bc110-8369-43b1-9722-c9a61d6373fc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Paragraphs1</th>\n","      <th>Paragraphs2</th>\n","      <th>Truth_changes</th>\n","      <th>file_number</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In general, be courteous to others. Debate/dis...</td>\n","      <td>My goodness. The poor woman can’t even get her...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>My goodness. The poor woman can’t even get her...</td>\n","      <td>Exactly. If Sicknik had \"recovered\" that day a...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Exactly. If Sicknik had \"recovered\" that day a...</td>\n","      <td>r/politics is currently accepting new moderato...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>r/politics is currently accepting new moderato...</td>\n","      <td>Essentially, if someone commits a tort, like a...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Essentially, if someone commits a tort, like a...</td>\n","      <td>I am a bot, and this action was performed auto...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>51988</th>\n","      <td>This is genocide, the destruction of a people ...</td>\n","      <td>Either way, we agree that what Russia is doing...</td>\n","      <td>1</td>\n","      <td>999</td>\n","    </tr>\n","    <tr>\n","      <th>51989</th>\n","      <td>Either way, we agree that what Russia is doing...</td>\n","      <td>Apologies for being pedantic here, I agree wit...</td>\n","      <td>0</td>\n","      <td>999</td>\n","    </tr>\n","    <tr>\n","      <th>51990</th>\n","      <td>Apologies for being pedantic here, I agree wit...</td>\n","      <td>Exactly! This is no place for Euphemisms, Russ...</td>\n","      <td>0</td>\n","      <td>999</td>\n","    </tr>\n","    <tr>\n","      <th>51991</th>\n","      <td>Exactly! This is no place for Euphemisms, Russ...</td>\n","      <td>The boy children will be trained for war and t...</td>\n","      <td>1</td>\n","      <td>999</td>\n","    </tr>\n","    <tr>\n","      <th>51992</th>\n","      <td>The boy children will be trained for war and t...</td>\n","      <td>Their population growth is stagnant for over o...</td>\n","      <td>0</td>\n","      <td>999</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>51993 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a00bc110-8369-43b1-9722-c9a61d6373fc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a00bc110-8369-43b1-9722-c9a61d6373fc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a00bc110-8369-43b1-9722-c9a61d6373fc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-008ffbf6-0e25-4fbb-a239-a0b856322486\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-008ffbf6-0e25-4fbb-a239-a0b856322486')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-008ffbf6-0e25-4fbb-a239-a0b856322486 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                                             Paragraphs1  \\\n","0      In general, be courteous to others. Debate/dis...   \n","1      My goodness. The poor woman can’t even get her...   \n","2      Exactly. If Sicknik had \"recovered\" that day a...   \n","3      r/politics is currently accepting new moderato...   \n","4      Essentially, if someone commits a tort, like a...   \n","...                                                  ...   \n","51988  This is genocide, the destruction of a people ...   \n","51989  Either way, we agree that what Russia is doing...   \n","51990  Apologies for being pedantic here, I agree wit...   \n","51991  Exactly! This is no place for Euphemisms, Russ...   \n","51992  The boy children will be trained for war and t...   \n","\n","                                             Paragraphs2  Truth_changes  \\\n","0      My goodness. The poor woman can’t even get her...              1   \n","1      Exactly. If Sicknik had \"recovered\" that day a...              1   \n","2      r/politics is currently accepting new moderato...              1   \n","3      Essentially, if someone commits a tort, like a...              1   \n","4      I am a bot, and this action was performed auto...              1   \n","...                                                  ...            ...   \n","51988  Either way, we agree that what Russia is doing...              1   \n","51989  Apologies for being pedantic here, I agree wit...              0   \n","51990  Exactly! This is no place for Euphemisms, Russ...              0   \n","51991  The boy children will be trained for war and t...              1   \n","51992  Their population growth is stagnant for over o...              0   \n","\n","       file_number  \n","0                1  \n","1                1  \n","2                1  \n","3                1  \n","4                1  \n","...            ...  \n","51988          999  \n","51989          999  \n","51990          999  \n","51991          999  \n","51992          999  \n","\n","[51993 rows x 4 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(TRAIN_CSV)\n","\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3PQylajTS-J"},"outputs":[],"source":["from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -> str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrBDMJU5TUfH"},"outputs":[],"source":["df['Paragraphs1'] = df['Paragraphs1'].apply(lambda x : resolve_encodings_and_normalize(x))\n","df['Paragraphs2'] = df['Paragraphs2'].apply(lambda x : resolve_encodings_and_normalize(x))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSLSIM4KUttb"},"outputs":[],"source":["# gkf = KFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# gkf = GroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","gkf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# gkf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","\n","for fold, (train_id, val_id) in enumerate(gkf.split(X=df, y=df.Truth_changes, groups=df.file_number)):\n","    # For all row in val_id list => create kfold column value\n","    df.loc[val_id , \"kfold\"] = fold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1714388699609,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"yaRSJyvEVSBK","outputId":"a105f323-7002-4733-c627-242ecfb992a7"},"outputs":[{"data":{"text/plain":["kfold  Truth_changes\n","0.0    1                10503\n","       0                 6828\n","1.0    1                10503\n","       0                 6828\n","2.0    1                10502\n","       0                 6829\n","Name: count, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby('kfold')['Truth_changes'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vkYju2mYXS_j"},"outputs":[],"source":["class RedditDataset(Dataset):\n","    def __init__(self, df, max_length, tokenizer, training=True):\n","        self.df = df\n","        self.max_len = max_length\n","        self.tokenizer = tokenizer\n","        self.paragraphs1 = self.df['Paragraphs1'].values\n","        self.paragraphs2 = self.df['Paragraphs2'].values\n","        self.training = training\n","\n","        if self.training:\n","            self.targets = self.df['Truth_changes'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        paragraphs1 = self.paragraphs1[index]\n","        paragraphs2 = self.paragraphs2[index]\n","\n","        inputs = self.tokenizer.encode_plus(\n","            paragraphs1,\n","            paragraphs2,\n","            truncation = True,\n","            add_special_tokens = True,\n","            max_length = self.max_len\n","        )\n","\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","        }\n","\n","        if self.training:\n","            samples['target'] = self.targets[index]\n","\n","        return samples\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1714388700024,"user":{"displayName":"Alessandro Corona","userId":"04916208375039160031"},"user_tz":-120},"id":"A9-yQthFZpUy","outputId":"08b16916-8f13-4d04-c62a-d40ab293b27b"},"outputs":[{"data":{"text/plain":["{'input_ids': [1, 5365, 447, 2, 5365, 447, 2], 'token_type_ids': [0, 0, 0, 0, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["CFG.tokenizer.encode_plus(\n","            \"Hello world\",\n","            \"Hello world\",\n","            truncation = True,\n","            add_special_tokens = True,\n","            max_length = 200\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYvY5rJaZ5yd"},"outputs":[],"source":["# Dynamic Padding (Collate)\n","class Collate:\n","    def __init__(self, tokenizer, isTrain=True):\n","        self.tokenizer = tokenizer\n","        self.isTrain = isTrain\n","        # self.args = args\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","        if self.isTrain:\n","            output[\"target\"] = [sample[\"target\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","        if self.isTrain:\n","            output[\"target\"] = torch.tensor(output[\"target\"], dtype=torch.long)\n","\n","        return output\n","\n","# collate_fn = DataCollatorWithPadding(tokenizer=CFG.tokenizer)\n","collate_fn = Collate(CFG.tokenizer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2tM5dhpalCF"},"outputs":[],"source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","\n","        return mean_embeddings\n","\n","class MeanMaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanMaxPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        mean_pooling_embeddings = torch.mean(last_hidden_state, 1)\n","        _, max_pooling_embeddings = torch.max(last_hidden_state, 1)\n","        mean_max_embeddings = torch.cat((mean_pooling_embeddings, max_pooling_embeddings), 1)\n","        return mean_max_embeddings\n","\n","\n","class LSTMPooling(nn.Module):\n","    def __init__(self, num_layers, hidden_size, hiddendim_lstm):\n","        super(LSTMPooling, self).__init__()\n","        self.num_hidden_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.hiddendim_lstm = hiddendim_lstm\n","        self.lstm = nn.LSTM(self.hidden_size, self.hiddendim_lstm, batch_first=True)\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, all_hidden_states):\n","        ## forward\n","        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n","                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n","        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n","        out, _ = self.lstm(hidden_states, None)\n","        out = self.dropout(out[:, -1, :])\n","        return out\n","\n","class WeightedLayerPooling(nn.Module):\n","    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n","        super(WeightedLayerPooling, self).__init__()\n","        self.layer_start = layer_start\n","        self.num_hidden_layers = num_hidden_layers\n","        self.layer_weights = layer_weights if layer_weights is not None \\\n","            else nn.Parameter(\n","                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n","            )\n","\n","    def forward(self, all_hidden_states):\n","        all_layer_embedding = torch.stack(list(all_hidden_states), dim=0)\n","        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :]\n","        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n","        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n","        return weighted_average\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qOdw-I0avwC"},"outputs":[],"source":["class MultiSampleDropout(nn.Module):\n","    # Multisample Dropout: https://arxiv.org/abs/1905.09788\n","    def __init__(self, classifier, start_prob=0.2, num_samples=8, increment=0.01):\n","        super(MultiSampleDropout, self).__init__()\n","        #self.dropout = nn.Dropout\n","        self.dropouts = [StableDropout(start_prob + (increment*i)) for i in range(num_samples)]\n","        self.classifier = classifier\n","\n","    def forward(self, out):\n","        return torch.mean(torch.stack([\n","            self.classifier(dropout(out)) for dropout in self.dropouts\n","        ], dim=0), dim=0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7wHlgRRa-rC"},"outputs":[],"source":["class MultiAuthorModel(nn.Module):\n","    def __init__(self, model_name):\n","        super(MultiAuthorModel, self).__init__()\n","\n","        # DeBERTa\n","        self.model = AutoModel.from_pretrained(model_name)\n","        self.config = AutoConfig.from_pretrained(model_name)\n","\n","        # gradient checkpointing\n","        if CFG.gradient_checkpoint:\n","            self.model.gradient_checkpointing_enable()\n","            print(f\"Gradient Checkpointing: {self.model.is_gradient_checkpointing}\")\n","\n","        # freezing embeddings and first 6 layers of encoder\n","        if  CFG.freezing:\n","            freeze(self.model.embeddings)\n","            freeze(self.model.encoder.layer[:6])\n","\n","        # Pooling\n","        #self.weighted_pooler = WeightedLayerPooling(num_hidden_layers=self.config.num_hidden_layers, layer_start=4)\n","        #self.pooler = MeanPooling()\n","\n","        self.context_pooler = ContextPooler(self.config)\n","\n","        #self.bilstm = nn.LSTM(self.config.hidden_size, self.config.hidden_size//2, num_layers=2,\n","        #                      dropout=self.config.hidden_dropout_prob, batch_first=True,\n","        #                      bidirectional=False)\n","\n","        #self.drop = nn.Dropout(p=0.2)\n","\n","        # Multi Sample Dropout\n","        self.fc = nn.Linear(self.config.hidden_size, CFG.num_classes)\n","        self.multi_sample_dropout = MultiSampleDropout(self.fc, start_prob=CFG.dropout, num_samples=8, increment=0.01)\n","\n","    def forward(self, ids, mask):\n","        out = self.model(input_ids=ids,attention_mask=mask,\n","                        output_hidden_states=True)\n","\n","        # out = self.weighted_pooler(out.hidden_states) # For WeightedLayerPooling\n","        # out = self.pooler(out, mask) # For MeanPooling\n","\n","        #out = self.context_pooler(torch.stack(list(out.hidden_states), dim=0)) # For ContextPooler\n","        out = self.context_pooler(out[0]) # For ContextPooler\n","\n","        # out = self.pooler(out.last_hidden_state, mask)\n","\n","        outputs = self.multi_sample_dropout(out)\n","\n","        #out = self.pooler(out.last_hidden_state, mask)\n","        #out = self.bilstm(out)[0]\n","        #out = self.drop(out)\n","        #outputs = self.fc(out)\n","\n","        return outputs\n","\n","    def set_optimizer_scheduler(self, option=\"Adam8bit\"):\n","        if option == \"AdamW\":\n","            model_parameters = filter(lambda parameter: parameter.requires_grad, self.parameters())\n","\n","            # Optimizer and scheduler\n","            optimizer = AdamW(model_parameters, lr=CFG.learning_rate, weight_decay = CFG.weight_decay)\n","            scheduler = fetch_scheduler(optimizer)\n","        elif option == \"Adam8bit\":\n","            # Adam 8-bits optimizer\n","            no_decay = [\"bias\", \"LayerNorm.weight\"]\n","            optimizer_grouped_parameters = [\n","                {\n","                    \"params\": [p for n, p in self.named_parameters() if not any(nd in n for nd in no_decay) and p[1].requires_grad],\n","                    \"weight_decay\": CFG.weight_decay,\n","                },\n","                {\n","                    \"params\": [p for n, p in self.named_parameters() if any(nd in n for nd in no_decay) and p[1].requires_grad],\n","                    \"weight_decay\": 0.0,\n","                },\n","            ]\n","\n","            # initializing optimizer\n","            # bnb_optimizer = bnb.optim.AdamW(params=model_parameters, lr=CFG.learning_rate, weight_decay=CFG.weight_decay, optim_bits=8)\n","            optimizer = bnb.optim.Adam8bit(optimizer_grouped_parameters, lr=CFG.learning_rate)\n","            print(f\"8-bit Optimizer:\\n\\n{optimizer}\")\n","\n","            # setting embeddings parameters\n","            # set_embedding_parameters_bits(embeddings_path=self.model.embeddings)\n","\n","            scheduler = fetch_scheduler(optimizer)\n","        else:\n","            embedding_parameters = filter(lambda parameter: parameter.requires_grad, self.model.parameters())\n","\n","            optimizer_model = AdamW(embedding_parameters, lr=5e-6, weight_decay = CFG.weight_decay)\n","            optimizer_linear = AdamW(model.fc.parameters(), lr=1e-4, weight_decay = CFG.weight_decay)\n","\n","            scheduler_model = fetch_scheduler(optimizer_model)\n","            scheduler_linear = fetch_scheduler(optimizer_linear)\n","\n","            optimizer = [optimizer_model, optimizer_linear]\n","            scheduler = [scheduler_model, scheduler_linear]\n","\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","        return True\n","\n","    def get_optimizer_scheduler(self):\n","        return self.optimizer, self.scheduler\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6E5KABBci5e"},"outputs":[],"source":["class LabelSmoothing(nn.Module):\n","    \"Implement label smoothing.\"\n","    def __init__(self, size, padding_idx, smoothing=0.0):\n","        super(LabelSmoothing, self).__init__()\n","        self.criterion = nn.KLDivLoss(reduction='sum')\n","        self.padding_idx = padding_idx\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.size = size\n","        self.true_dist = None\n","\n","    def forward(self, x, target):\n","        assert x.size(1) == self.size\n","        true_dist = x.data.clone()\n","        true_dist.fill_(self.smoothing / (self.size - 2))\n","        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        true_dist[:, self.padding_idx] = 0\n","        mask = torch.nonzero(target.data == self.padding_idx)\n","        if mask.dim() > 0:\n","            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n","        self.true_dist = true_dist\n","        return self.criterion(x, Variable(true_dist, requires_grad=False))\n","\n","# criterion = LabelSmoothing(size=3, padding_idx=CFG.tokenizer.pad_token_id, smoothing=0.1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lXrPknHcrhb"},"outputs":[],"source":["def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaeUpyAecyYA"},"outputs":[],"source":["def train_one_epoch(model, dataloader, device, epoch):\n","    model.train()\n","    dataset_size = 0\n","    running_loss= 0\n","    type_running_loss = 0\n","    effect_running_loss = 0\n","    epoch_loss=0\n","\n","    optimizer, scheduler = model.get_optimizer_scheduler()\n","\n","    bar = tqdm(enumerate(dataloader), total= len(dataloader))\n","    for step, data in bar:\n","        ids = data['input_ids'].to(device, dtype = torch.long)\n","        mask = data['attention_mask'].to(device, dtype = torch.long)\n","\n","        targets = data['target'].to(device, dtype = torch.long)\n","\n","        batch_size = ids.size(0)\n","        outputs = model(ids, mask)\n","        loss = criterion(outputs, targets)\n","        loss = loss/CFG.n_accumulate\n","        loss.backward()\n","\n","        if (step+1)% CFG.n_accumulate ==0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            scheduler.step()\n","\n","        running_loss += (loss.item()*batch_size) * CFG.n_accumulate\n","        effect_running_loss += (loss.item()*batch_size)\n","\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","        type_epoch_loss = type_running_loss / dataset_size\n","        effect_epoch_loss = effect_running_loss / dataset_size\n","\n","        wandb.log({'Train Combine Loss': epoch_loss})\n","        wandb.log({'Train Type Loss': type_epoch_loss})\n","        wandb.log({'Train Effect Loss': effect_epoch_loss})\n","\n","        wandb.log({'Train Effect Loss1': loss.item()})\n","\n","        bar.set_postfix(Epoch = epoch, Train_loss = epoch_loss, Effect_loss = loss.item(), LR=optimizer.param_groups[0]['lr'])\n","        # bar.set_postfix(Epoch = epoch, Train_loss = epoch_loss)\n","    gc.collect()\n","    return epoch_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EMHCUhBf-gr"},"outputs":[],"source":["@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","\n","    dataset_size = 0\n","    running_loss= 0\n","\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        ids = data['input_ids'].to(device, dtype = torch.long)\n","        mask = data['attention_mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype = torch.long)\n","\n","        batch_size = ids.size(0)\n","        outputs = model(ids, mask)\n","        loss = criterion(outputs, targets)\n","\n","        running_loss += (loss.item()*batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","#         bar.set_postfix(Epoch = epoch, Valid_loss = epoch_loss, LR=optimizer.param_groups[0]['lr'])\n","        bar.set_postfix(Epoch = epoch, Valid_loss = epoch_loss)\n","    gc.collect()\n","    return epoch_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jRZxaJrfgNgQ"},"outputs":[],"source":["def prepare_loaders(fold):\n","    df_train = df[df['kfold'] != fold].reset_index(drop=True)\n","    df_valid = df[df['kfold'] == fold].reset_index(drop=True)\n","\n","    train_dataset = RedditDataset(df_train, tokenizer=CFG.tokenizer, max_length=CFG.max_length)\n","    valid_dataset = RedditDataset(df_valid, tokenizer=CFG.tokenizer, max_length=CFG.max_length)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=CFG.train_batch_size, collate_fn=collate_fn,\n","                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_batch_size, collate_fn=collate_fn,\n","                              num_workers=2, shuffle=False, pin_memory=True)\n","\n","    return train_loader, valid_loader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHd5S0yXgb_t"},"outputs":[],"source":["def fetch_scheduler(optimizer):\n","    if CFG.scheduler == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr)\n","    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = CFG.T_0, eta_min=CFG.min_lr)\n","    elif CFG.scheduler == None:\n","        return None\n","    return scheduler\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMjFOzppgh8K"},"outputs":[],"source":["def run_training(model, device, num_epochs, fold, train_loader, valid_loader):\n","    wandb.watch(model, log_freq = 100)\n","\n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = np.inf\n","    history = defaultdict(list)\n","    for epoch in range(1,num_epochs+1):\n","        gc.collect()\n","        train_epoch_loss = train_one_epoch(model,train_loader, device, epoch)\n","        valid_epoch_loss = valid_one_epoch(model, valid_loader, device, epoch)\n","\n","        history['Train Loss'].append(train_epoch_loss)\n","        history['Eval Loss'].append(valid_epoch_loss)\n","\n","        wandb.log({'Train Loss': train_epoch_loss})\n","        wandb.log({'Eval Loss': valid_epoch_loss})\n","\n","        if valid_epoch_loss <= best_epoch_loss:\n","            print(f\"Valid Loss Improved: {best_epoch_loss} -------> {valid_epoch_loss}\")\n","            best_epoch_loss = valid_epoch_loss\n","            run.summary['Best Loss']= best_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            path = 'weights/DeBERTa' + f'LossFold-{fold}.bin'\n","            torch.save(model.state_dict(), path)\n","            print('Model Saved')\n","\n","    end = time.time()\n","    time_eclipsed = end-start\n","    print(f'Time complete in: {time_eclipsed//3600}h:{(time_eclipsed%3600)//60}m:{time_eclipsed%60}s')\n","    print(f'Best Loss: {best_epoch_loss}')\n","\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e3a5513d50d848e28cb7e8411914fa19","02f68740d9874bc3a97b29f6cdd23201","eb29c4a277f64639b04a9816a55f7c11","3475fa0b73364776bdc130e46110c37f","3427788dcafa41f4b4eb00ceb6a8bc1f","cde018246a0c4da480ada5b0b40c48b1","a9881bcc5a3b4654a0934dce9933d8aa","d9e90969f77043d699d8e9a09ee24096","73a4875e944f44afacb48d9c0440025b","487a78f30abd4a76b787f12d97ed284b","5883816152c443f5accba5a51affed7e","4ba47429ea354ae19da5d19bd8ee8e76","e0c2898ddf4f48c99825f9e72e72ac81","be5f72d0386b4cd685343ddd4be3ff59","ce9fa767feed487985c122454d355e6e","3e18cf778cbe4f4d9542af8d7f5fed43","17812346fdf348b193776fe642ed75ba","580e2fd0ab274e619086954040c67adc","ea15cc5b8c854d8389cf8ddd4b8abeb4"]},"id":"Cj_eaeKigs_a","outputId":"84ee64fb-1d2a-469e-c689-399e3c412fdf"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malessandro-corona-m\u001b[0m (\u001b[33malessandro-corona\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"name":"stdout","output_type":"stream","text":["================ Fold: 0 =================\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20240429_110459-eyxr6ktr</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/alessandro-corona/Multi-author/runs/eyxr6ktr' target=\"_blank\">PL1714388357-Fold-0</a></strong> to <a href='https://wandb.ai/alessandro-corona/Multi-author' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/alessandro-corona/Multi-author' target=\"_blank\">https://wandb.ai/alessandro-corona/Multi-author</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/alessandro-corona/Multi-author/runs/eyxr6ktr' target=\"_blank\">https://wandb.ai/alessandro-corona/Multi-author/runs/eyxr6ktr</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3a5513d50d848e28cb7e8411914fa19","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Gradient Checkpointing: True\n","[INFO] Using GPU: Tesla T4\n","\n","8-bit Optimizer:\n","\n","Adam8bit (\n","Parameter Group 0\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 1e-05\n","    weight_decay: 0.005\n","\n","Parameter Group 1\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 1e-05\n","    weight_decay: 0.0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 2166/2166 [39:46<00:00,  1.01it/s, Effect_loss=0.305, Epoch=1, LR=9.4e-6, Train_loss=0.507]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 2166/2166 [39:47<00:00,  1.10s/it, Effect_loss=0.305, Epoch=1, LR=9.4e-6, Train_loss=0.507]\n","100%|██████████| 542/542 [05:58<00:00,  1.51it/s, Epoch=1, Valid_loss=0.451]\n"]},{"name":"stdout","output_type":"stream","text":["Valid Loss Improved: inf -------> 0.45101842585303875\n","Model Saved\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2166/2166 [39:50<00:00,  1.10s/it, Effect_loss=0.214, Epoch=2, LR=7.77e-6, Train_loss=0.443]\n","100%|██████████| 542/542 [05:58<00:00,  1.51it/s, Epoch=2, Valid_loss=0.424]\n"]},{"name":"stdout","output_type":"stream","text":["Valid Loss Improved: 0.45101842585303875 -------> 0.4240165781998179\n","Model Saved\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2166/2166 [39:52<00:00,  1.10s/it, Effect_loss=0.0727, Epoch=3, LR=5.53e-6, Train_loss=0.41]\n","100%|██████████| 542/542 [05:59<00:00,  1.51it/s, Epoch=3, Valid_loss=0.425]\n","100%|██████████| 2166/2166 [39:49<00:00,  1.10s/it, Effect_loss=0.109, Epoch=4, LR=3.28e-6, Train_loss=0.381]\n","100%|██████████| 542/542 [05:59<00:00,  1.51it/s, Epoch=4, Valid_loss=0.415]\n"]},{"name":"stdout","output_type":"stream","text":["Valid Loss Improved: 0.4240165781998179 -------> 0.41476610681408244\n","Model Saved\n","Time complete in: 3.0h:3.0m:41.671417474746704s\n","Best Loss: 0.41476610681408244\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ba47429ea354ae19da5d19bd8ee8e76","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Eval Loss</td><td>█▃▃▁</td></tr><tr><td>Train Combine Loss</td><td>█▇▆▅▅▅▅▅▄▄▁▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Effect Loss</td><td>█▇▆▅▅▅▅▅▄▄▁▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Effect Loss1</td><td>█▆▄▆▄▄▂▅▅▄▂▆▅▄▃▃▅▆▅▅▂▃▃▃▄▅▅▃▅▄▃▁▅▆▂▂▃▃▆▃</td></tr><tr><td>Train Loss</td><td>█▄▃▁</td></tr><tr><td>Train Type Loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Loss</td><td>0.41477</td></tr><tr><td>Eval Loss</td><td>0.41477</td></tr><tr><td>Train Combine Loss</td><td>0.38094</td></tr><tr><td>Train Effect Loss</td><td>0.19047</td></tr><tr><td>Train Effect Loss1</td><td>0.10861</td></tr><tr><td>Train Loss</td><td>0.38094</td></tr><tr><td>Train Type Loss</td><td>0.0</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">PL1714388357-Fold-0</strong> at: <a href='https://wandb.ai/alessandro-corona/Multi-author/runs/eyxr6ktr' target=\"_blank\">https://wandb.ai/alessandro-corona/Multi-author/runs/eyxr6ktr</a><br/> View project at: <a href='https://wandb.ai/alessandro-corona/Multi-author' target=\"_blank\">https://wandb.ai/alessandro-corona/Multi-author</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240429_110459-eyxr6ktr/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["================ Fold: 1 =================\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20240429_140854-qyryrdpd</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/alessandro-corona/Multi-author/runs/qyryrdpd' target=\"_blank\">PL1714388357-Fold-1</a></strong> to <a href='https://wandb.ai/alessandro-corona/Multi-author' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/alessandro-corona/Multi-author' target=\"_blank\">https://wandb.ai/alessandro-corona/Multi-author</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/alessandro-corona/Multi-author/runs/qyryrdpd' target=\"_blank\">https://wandb.ai/alessandro-corona/Multi-author/runs/qyryrdpd</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Gradient Checkpointing: True\n","[INFO] Using GPU: Tesla T4\n","\n","8-bit Optimizer:\n","\n","Adam8bit (\n","Parameter Group 0\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 1e-05\n","    weight_decay: 0.005\n","\n","Parameter Group 1\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 1e-05\n","    weight_decay: 0.0\n",")\n"]},{"name":"stderr","output_type":"stream","text":[" 97%|█████████▋| 2102/2166 [38:59<01:11,  1.12s/it, Effect_loss=0.212, Epoch=1, LR=9.77e-6, Train_loss=0.514]"]}],"source":["transformers.logging.set_verbosity_error()\n","for fold in range(CFG.n_fold):\n","    print(f'================ Fold: {fold} =================')\n","\n","    cfg = dict(CFG.__dict__)\n","    del cfg['__dict__'], cfg['__weakref__']\n","    run = wandb.init(\n","        project = 'Multi-author',\n","        config = cfg,\n","        job_type = 'Train',\n","        group = CFG.group,\n","        tags = [CFG.model_name, CFG.wandb_id],\n","        name = f'{CFG.wandb_id}-Fold-{fold}',\n","        anonymous='must'\n","    )\n","\n","    train_loader, valid_loader = prepare_loaders(fold)\n","    model = MultiAuthorModel(CFG.model_name)\n","    model.to(CFG.device)\n","\n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","\n","    model.set_optimizer_scheduler(\"Adam8bit\")\n","\n","    model, history = run_training(model, CFG.device, CFG.epoch, fold, train_loader, valid_loader)\n","\n","    run.finish()\n","    gc.collect()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCYZjocUqpVQ"},"outputs":[],"source":["import warnings,transformers,logging,torch\n","\n","warnings.simplefilter('ignore')\n","logging.disable(logging.WARNING)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMCtOM_Iqu2P"},"outputs":[],"source":["test_df = pd.read_csv(TEST_CSV)\n","\n","test_df.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JmUt5s8sG3x"},"outputs":[],"source":["class RedditTestDataset(Dataset):\n","    def __init__(self,df, max_length, tokenizer):\n","        self.df = df\n","        self.max_len = max_length\n","        self.tokenizer = tokenizer\n","        self.paragraphs1 = self.df['Paragraphs1'].values\n","        self.paragraphs2 = self.df['Paragraphs2'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        paragraphs1 = self.discourse_type[index]\n","        paragraphs2 = self.discourse_text[index]\n","\n","        inputs = self.tokenizer.encode_plus(\n","            paragraphs1,\n","            paragraphs2,\n","            truncation = True,\n","            add_special_tokens = True,\n","            max_length = self.max_len\n","        )\n","\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","        }\n","\n","        return samples\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FnMrjErussLr"},"outputs":[],"source":["collate_fn = DataCollatorWithPadding(tokenizer=CFG.tokenizer)\n","\n","softmax = nn.Softmax(dim=1)\n","model = MultiAuthorModel(CFG.model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SL7VrPmWtHzQ"},"outputs":[],"source":["def prepare_test_loader(test_df):\n","    test_dataset = RedditDataset(test_df,\n","                                   tokenizer=CFG.tokenizer,\n","                                   max_length=CFG.max_length,\n","                                   training=False)\n","\n","    test_loader = DataLoader(test_dataset,\n","                             batch_size=CFG.valid_batch_size,\n","                             collate_fn=collate_fn,\n","                             num_workers=2,\n","                             shuffle=False,\n","                             pin_memory=True,\n","                             drop_last=False)\n","    return test_loader\n","\n","test_loader = prepare_test_loader(test_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ju_E2JMstYHh"},"outputs":[],"source":["@torch.no_grad()\n","def inference(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","\n","    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n","\n","    for step, data in bar:\n","        ids = data['input_ids'].to(device, dtype = torch.long)\n","        mask = data['attention_mask'].to(device, dtype = torch.long)\n","\n","        output = model(ids, mask)\n","        y_preds = softmax(torch.tensor(output.to('cpu'))).numpy()\n","\n","        preds.append(y_preds)\n","\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zw_yQPGbtfow"},"outputs":[],"source":["deberta_predictions = []\n","\n","for fold in range(CFG.n_fold):\n","    print(\"Fold {}\".format(fold))\n","    path = 'data/weights/' + f'Hard-LossFold-{fold}.bin'\n","    state = torch.load(path)\n","    model.load_state_dict(state)\n","\n","    prediction = inference(test_loader, model, CFG.device)\n","    deberta_predictions.append(prediction)\n","    del state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","\n","del model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_r4p4nMKtkHX"},"outputs":[],"source":["deberta_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PsrE_xIyP_P-"},"outputs":[],"source":["predictions = np.mean(deberta_predictions, axis=0)\n","predictions.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gcDMWghQMWr"},"outputs":[],"source":["test_df['pred_0'] = predictions[:, 0]\n","test_df['pred_1'] = predictions[:, 1]\n","test_df['prediction'] = 0\n","test_df.loc[test_df['pred_0'] <= test_df['pred_1'], 'prediction'] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kl-VsMI0Q3rQ"},"outputs":[],"source":["test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DurFzgmSO29"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","y_true = test_df['Truth_changes'].values  # Ground truth labels\n","y_pred = test_df['prediction'].values  # Predicted labels\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_true, y_pred)\n","\n","# Calculate precision\n","precision = precision_score(y_true, y_pred)\n","\n","# Calculate recall\n","recall = recall_score(y_true, y_pred)\n","\n","# Calculate F1-score\n","f1 = f1_score(y_true, y_pred)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hgkl86dWTPqP"},"outputs":[],"source":["filtered_df = test_df[test_df['Truth_changes'] != test_df['prediction']]\n","filtered_df_goods = test_df[test_df['Truth_changes'] == test_df['prediction']]\n","\n","fn = filtered_df.loc[filtered_df['prediction'] == 0, 'pred_0']\n","fp = filtered_df.loc[filtered_df['prediction'] == 1, 'pred_1']\n","tn = filtered_df_goods.loc[filtered_df_goods['prediction'] == 0, 'pred_0']\n","tp = filtered_df_goods.loc[filtered_df_goods['prediction'] == 1, 'pred_1']\n","\n","vecs = {\"False negatives\": fn, \"False positives\": fp, \"True negatives\": tn, \"True positives\": tp}\n","\n","print(\"Analysis\")\n","print()\n","\n","for key, vec in vecs.items():\n","  print(key)\n","  print()\n","  mean = np.mean(vec)\n","  median = np.median(vec)\n","  std_dev = np.std(vec)\n","  variance = np.var(vec)\n","  minimum = np.min(vec)\n","  maximum = np.max(vec)\n","  print(\"Qty:\", len(vec))\n","  print(\"Mean:\", mean)\n","  print(\"Median:\", median)\n","  print(\"Standard Deviation:\", std_dev)\n","  print(\"Variance:\", variance)\n","  print(\"Minimum:\", minimum)\n","  print(\"Maximum:\", maximum)\n","  print()\n","\n","# Print the calculated statistics"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN7qMgjYxzBoITNzh4KWL5k","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02f68740d9874bc3a97b29f6cdd23201":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cde018246a0c4da480ada5b0b40c48b1","placeholder":"​","style":"IPY_MODEL_a9881bcc5a3b4654a0934dce9933d8aa","value":"pytorch_model.bin: 100%"}},"1245849d543840e19579d979d3fae178":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17812346fdf348b193776fe642ed75ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"197a8b682120422ba57f7d9d22e2359d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d794d0897b141028fd148785fecf750":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfd95812caf942c2a003eb6f2ea7065a","IPY_MODEL_fe356aea8e544c8db287570186264cc9","IPY_MODEL_8f009bb89214484fa8fd60b4f94239d7"],"layout":"IPY_MODEL_1245849d543840e19579d979d3fae178"}},"24485f84b9994abeb7d4ab115657a6e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26afc87c74294211bc128d57d5e23c04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31bd8b171f9a44df9a7db0289d5f17a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32bef58805ad4aa9bd0f30529b200763":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3427788dcafa41f4b4eb00ceb6a8bc1f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3475fa0b73364776bdc130e46110c37f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_487a78f30abd4a76b787f12d97ed284b","placeholder":"​","style":"IPY_MODEL_5883816152c443f5accba5a51affed7e","value":" 371M/371M [00:02&lt;00:00, 178MB/s]"}},"3e18cf778cbe4f4d9542af8d7f5fed43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41f0b54f230d4ece8f7c352bd91932a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"487a78f30abd4a76b787f12d97ed284b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ba47429ea354ae19da5d19bd8ee8e76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e0c2898ddf4f48c99825f9e72e72ac81","IPY_MODEL_be5f72d0386b4cd685343ddd4be3ff59"],"layout":"IPY_MODEL_ce9fa767feed487985c122454d355e6e"}},"505f52e3f54e45269e83f44deeeb816a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b7086a1959340b2b3633153f3923c09","IPY_MODEL_940dc8cbfedc4dc0bac54f7b0ff5853c","IPY_MODEL_6982c089339842fa9930b99cf0827c8b"],"layout":"IPY_MODEL_873cbeecb91e41148a920e2545f04094"}},"57b522f2a18e4056827e041d7fcdd49e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90420d5cad4a495da4fa80ac667ed1a8","IPY_MODEL_dc2483b5e5dc470d935fe9c37829c82a","IPY_MODEL_69220dd2fffc48f586ebe975e3a017c9"],"layout":"IPY_MODEL_eda173525ec84715ba80fa3e1d2c8e41"}},"580e2fd0ab274e619086954040c67adc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5883816152c443f5accba5a51affed7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"622de59072804732916c20fd04478820":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69220dd2fffc48f586ebe975e3a017c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_daaf4dd6cb8a495982c18678512325e7","placeholder":"​","style":"IPY_MODEL_83ee34a8caf040b399294a76a9f54d82","value":" 579/579 [00:00&lt;00:00, 15.5kB/s]"}},"6982c089339842fa9930b99cf0827c8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31bd8b171f9a44df9a7db0289d5f17a2","placeholder":"​","style":"IPY_MODEL_7c43b4a2df6e4ae89b3aa5ff9bee76aa","value":" 2.46M/2.46M [00:00&lt;00:00, 21.8MB/s]"}},"73a4875e944f44afacb48d9c0440025b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78739ba341284a1a8ebc734d09fa4d12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b7086a1959340b2b3633153f3923c09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41f0b54f230d4ece8f7c352bd91932a1","placeholder":"​","style":"IPY_MODEL_9a64385da46547cba7004202a8bc631a","value":"spm.model: 100%"}},"7c43b4a2df6e4ae89b3aa5ff9bee76aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83ee34a8caf040b399294a76a9f54d82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"873cbeecb91e41148a920e2545f04094":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f009bb89214484fa8fd60b4f94239d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed8800f38ae74aeea28f296ba65511fa","placeholder":"​","style":"IPY_MODEL_f687bdfc939d4f3f84c829fc02a866f8","value":" 52.0/52.0 [00:00&lt;00:00, 1.36kB/s]"}},"90420d5cad4a495da4fa80ac667ed1a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968b7ecf72ae4eab8b6ad777f74cc605","placeholder":"​","style":"IPY_MODEL_622de59072804732916c20fd04478820","value":"config.json: 100%"}},"940dc8cbfedc4dc0bac54f7b0ff5853c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd7fb776a19d42b4a22177cb33051f26","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78739ba341284a1a8ebc734d09fa4d12","value":2464616}},"968b7ecf72ae4eab8b6ad777f74cc605":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98f27a8105f641f79b4de4a41893f8e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a64385da46547cba7004202a8bc631a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9881bcc5a3b4654a0934dce9933d8aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd7fb776a19d42b4a22177cb33051f26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be5f72d0386b4cd685343ddd4be3ff59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_580e2fd0ab274e619086954040c67adc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea15cc5b8c854d8389cf8ddd4b8abeb4","value":1}},"cde018246a0c4da480ada5b0b40c48b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce9fa767feed487985c122454d355e6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9e90969f77043d699d8e9a09ee24096":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"daaf4dd6cb8a495982c18678512325e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc2483b5e5dc470d935fe9c37829c82a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e98c25ef37c64069a627cd05390d8dbe","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98f27a8105f641f79b4de4a41893f8e3","value":579}},"dfd95812caf942c2a003eb6f2ea7065a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24485f84b9994abeb7d4ab115657a6e1","placeholder":"​","style":"IPY_MODEL_197a8b682120422ba57f7d9d22e2359d","value":"tokenizer_config.json: 100%"}},"e0c2898ddf4f48c99825f9e72e72ac81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e18cf778cbe4f4d9542af8d7f5fed43","placeholder":"​","style":"IPY_MODEL_17812346fdf348b193776fe642ed75ba","value":"0.210 MB of 0.210 MB uploaded\r"}},"e3a5513d50d848e28cb7e8411914fa19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02f68740d9874bc3a97b29f6cdd23201","IPY_MODEL_eb29c4a277f64639b04a9816a55f7c11","IPY_MODEL_3475fa0b73364776bdc130e46110c37f"],"layout":"IPY_MODEL_3427788dcafa41f4b4eb00ceb6a8bc1f"}},"e98c25ef37c64069a627cd05390d8dbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea15cc5b8c854d8389cf8ddd4b8abeb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb29c4a277f64639b04a9816a55f7c11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9e90969f77043d699d8e9a09ee24096","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73a4875e944f44afacb48d9c0440025b","value":371146213}},"ed8800f38ae74aeea28f296ba65511fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eda173525ec84715ba80fa3e1d2c8e41":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f687bdfc939d4f3f84c829fc02a866f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe356aea8e544c8db287570186264cc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26afc87c74294211bc128d57d5e23c04","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32bef58805ad4aa9bd0f30529b200763","value":52}}}}},"nbformat":4,"nbformat_minor":0}
